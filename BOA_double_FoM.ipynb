{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ee51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this block only if the modules below are not installed\n",
    "! pip install GPy\n",
    "! pip install sklearn\n",
    "! pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial import distance\n",
    "from scipy.special import erfc\n",
    "from scipy.stats import norm\n",
    "import GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21370384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting\n",
    "BOA = 1   # 1 or 2\n",
    "number_of_experiments_per_cycle = 5\n",
    "\n",
    "#Label in DoE_Exp_Table_double_FoM.xlsx\n",
    "output_label_main = \"TON\"\n",
    "output_label_sub = \"Chemoselectivity (%)\"\n",
    "\n",
    "#threshold of FoM 2\n",
    "threshold_sub = 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86a9d5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "xi = 0.01\n",
    "reject_rad = 1.\n",
    "core_opt = False\n",
    "\n",
    "if os.path.exists(\"./GP\"):\n",
    "    num = 1\n",
    "    while True:\n",
    "        if not os.path.exists(f\"./GP_prev{num}\"):\n",
    "            os.rename(\"./GP\", f\"./GP_prev{num}\")\n",
    "            break\n",
    "        else:\n",
    "            num += 1\n",
    "os.makedirs(\"./GP\", exist_ok=True)\n",
    "\n",
    "exp_table = pd.read_excel(\"./DoE_Exp_Table_double_FoM.xlsx\", index_col=0)\n",
    "exp_table.columns = [c.strip() for c in exp_table.columns]\n",
    "\n",
    "x_data_column = [c for c in exp_table.columns if not (c==output_label_main or c==output_label_sub)]\n",
    "print(f\"[Data read] factors: {x_data_column}\")\n",
    "\n",
    "reso = 11\n",
    "if len(x_data_column) > 6:\n",
    "    print(\"[CAUTION] The number of the factors is large. The search grid resolution is lowered.\")\n",
    "    reso -= 2*(len(x_data_column)-6)\n",
    "    print(f\"Resolution={reso} (default:11)\")\n",
    "if reso < 5:\n",
    "    print(\"[ERROR] The grid resolution is too low. Use sciCORE instead of this laptop.\")\n",
    "    print(\"System terminated.\")\n",
    "else:\n",
    "\n",
    "    min_li = [exp_table.loc[\"MIN\", c] for c in x_data_column]\n",
    "    max_li = [exp_table.loc[\"MAX\", c] for c in x_data_column]\n",
    "    min_max_li = np.array([min_li, max_li], dtype=float)\n",
    "\n",
    "    mmscaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "    mmscaler.fit(min_max_li)\n",
    "\n",
    "    exp_table = exp_table.drop([\"MIN\", \"MAX\"])\n",
    "    original_size = len(exp_table)\n",
    "    start = time.time()\n",
    "    \n",
    "    if BOA == 1:\n",
    "        for i in range(1, number_of_experiments_per_cycle+1):\n",
    "            print(f\"[Cycle {i}] {time.time()-start:.2f}[sec]\")\n",
    "            #print(exp_table)\n",
    "            x_train = mmscaler.transform(exp_table.loc[:,x_data_column].values)\n",
    "            y_main_train = exp_table.loc[:,[output_label_main]].values\n",
    "            y_sub_train = exp_table.loc[:,[output_label_sub]].values\n",
    "            #print(x_train); print(y_main_train); print(y_sub_train)\n",
    "\n",
    "            kern_main = GPy.kern.RBF(len(x_data_column), ARD=True)\n",
    "            gpy_model_main = GPy.models.GPRegression(X=x_train, Y=y_main_train, kernel=kern_main, normalizer=True)\n",
    "            if core_opt: gpy_model_main.optimize(messages=True, max_iters=1e5)\n",
    "\n",
    "            kern_sub = GPy.kern.RBF(len(x_data_column), ARD=True)\n",
    "            gpy_model_sub = GPy.models.GPRegression(X=x_train, Y=y_sub_train, kernel=kern_sub, normalizer=True)\n",
    "            if core_opt: gpy_model_sub.optimize(messages=True, max_iters=1e5)\n",
    "\n",
    "\n",
    "            lis = []\n",
    "            for j in range(len(x_data_column)):\n",
    "                lis += [np.linspace(0, 1.0, reso)]\n",
    "            points = np.array(list(itertools.product(*lis)))\n",
    "\n",
    "            minDist = distance.cdist(points, x_train, metric='euclidean').min(axis=1)\n",
    "            points = points[minDist>0.01]\n",
    "\n",
    "            if i > 1:\n",
    "                x_train_tentative = x_train[-(i-1):,:]\n",
    "                #print(x_train_tentative)\n",
    "                minDist = distance.cdist(points, x_train_tentative, metric='euclidean').min(axis=1)\n",
    "                points = points[minDist>reject_rad]\n",
    "\n",
    "            GO_table = pd.DataFrame(points, columns=[f\"{c}_S\" for c in x_data_column])\n",
    "\n",
    "            #Calculation of main acquisition function\n",
    "            pred_mean_main, pred_var_main = gpy_model_main.predict(points)\n",
    "            pred_mean_main = pred_mean_main.reshape(-1)\n",
    "            pred_std_main = np.sqrt(pred_var_main.reshape(-1))\n",
    "            GO_table[\"pred_mean_main\"] = pred_mean_main\n",
    "            GO_table[\"pred_std_main\"] = pred_std_main\n",
    "\n",
    "            mu_sample, _ = gpy_model_main.predict(x_train)\n",
    "            mu_sample_opt = np.max(mu_sample)\n",
    "\n",
    "            with np.errstate(divide='warn'):\n",
    "                imp = pred_mean_main - mu_sample_opt - xi\n",
    "                Z = imp / pred_std_main\n",
    "                ei = imp * norm.cdf(Z) + pred_std_main * norm.pdf(Z)\n",
    "                ei[pred_std_main == 0.] = 0.\n",
    "\n",
    "            GO_table[\"Acquisition_main\"] = ei\n",
    "\n",
    "            #Calculation of sub acquisition function\n",
    "            pred_mean_sub, pred_var_sub = gpy_model_sub.predict(points)\n",
    "            pred_mean_sub = pred_mean_sub.reshape(-1)\n",
    "            pred_std_sub = np.sqrt(pred_var_sub.reshape(-1))\n",
    "            GO_table[\"pred_mean_sub\"] = pred_mean_sub\n",
    "            GO_table[\"pred_std_sub\"] = pred_std_sub\n",
    "\n",
    "            #CFD of normal distribution (mu, std**2) from threshold_sub to infinity\n",
    "            erfc_param = -1 * (threshold_sub - pred_mean_sub) / (np.sqrt(2) * pred_std_sub)\n",
    "            GO_table[\"Acquisition_sub\"] = 1 - (0.5 * erfc(erfc_param))\n",
    "\n",
    "            #Calculation of total acquisition function\n",
    "            GO_table[\"Acquisition_total\"] = GO_table[\"Acquisition_main\"]*GO_table[\"Acquisition_sub\"]\n",
    "\n",
    "\n",
    "            for c in x_data_column:\n",
    "                GO_table[c] = 0.\n",
    "\n",
    "            GO_table.loc[:,x_data_column] = mmscaler.inverse_transform(points)\n",
    "\n",
    "            GO_table = GO_table.sort_values(\"Acquisition_total\", ascending=False)\n",
    "            GO_table[:1000].to_csv(f\"./GP/GP_{i}.csv\")\n",
    "\n",
    "            next_index = len(exp_table)+1\n",
    "            exp_table.loc[next_index] = -1\n",
    "            top_data = GO_table.iloc[0]\n",
    "            for clm in x_data_column:\n",
    "                exp_table.loc[next_index, clm] = top_data[clm]\n",
    "            exp_table.loc[next_index, output_label_main] = top_data[\"pred_mean_main\"]\n",
    "            exp_table.loc[next_index, output_label_sub] = top_data[\"pred_mean_sub\"]\n",
    "        \n",
    "        \n",
    "    elif BOA == 2:\n",
    "        for i in range(1, number_of_experiments_per_cycle+1):\n",
    "            print(f\"[Cycle {i}] {time.time()-start:.2f}[sec]\")\n",
    "            x_train = mmscaler.transform(exp_table.loc[:,x_data_column].values)\n",
    "            y_main_train_raw = exp_table.loc[:,[output_label_main]].values\n",
    "            y_sub_train = exp_table.loc[:,[output_label_sub]].values\n",
    "\n",
    "            #scaling y_main\n",
    "            y_main_scale_val = y_main_train_raw.max()/10.\n",
    "            y_main_train = y_main_train_raw/y_main_scale_val\n",
    "\n",
    "            kern_main = GPy.kern.RBF(len(x_data_column), ARD=True)\n",
    "            gpy_model_main = GPy.models.GPRegression(X=x_train, Y=y_main_train, kernel=kern_main, normalizer=True)\n",
    "            if core_opt: gpy_model_main.optimize(messages=True, max_iters=1e5)\n",
    "\n",
    "            kern_sub = GPy.kern.RBF(len(x_data_column), ARD=True)\n",
    "            gpy_model_sub = GPy.models.GPRegression(X=x_train, Y=y_sub_train, kernel=kern_sub, normalizer=True)\n",
    "            if core_opt: gpy_model_sub.optimize(messages=True, max_iters=1e5)\n",
    "\n",
    "            lis = []\n",
    "            for j in range(len(x_data_column)):\n",
    "                lis += [np.linspace(0, 1.0, reso)]\n",
    "            points = np.array(list(itertools.product(*lis)))\n",
    "\n",
    "            minDist = distance.cdist(points, x_train, metric='euclidean').min(axis=1)\n",
    "            points = points[minDist>0.01]\n",
    "\n",
    "            GO_table = pd.DataFrame(points, columns=[f\"{c}_S\" for c in x_data_column])\n",
    "\n",
    "\n",
    "            #Calculation of main acquisition function\n",
    "            pred_mean_main, pred_var_main = gpy_model_main.predict(points)\n",
    "            pred_mean_main = pred_mean_main.reshape(-1)\n",
    "            pred_std_main = pred_var_main.reshape(-1)\n",
    "            GO_table[\"pred_mean_main_real\"] = pred_mean_main*y_main_scale_val\n",
    "            GO_table[\"pred_mean_main_scaled\"] = pred_mean_main\n",
    "            GO_table[\"pred_std_main\"] = pred_std_main\n",
    "\n",
    "            mu_sample, _ = gpy_model_main.predict(x_train)\n",
    "            mu_sample_opt = np.max(mu_sample)\n",
    "\n",
    "            with np.errstate(divide='warn'):\n",
    "                imp = pred_mean_main - mu_sample_opt - xi\n",
    "                Z = imp / pred_std_main\n",
    "                ei = imp * norm.cdf(Z) + pred_std_main * norm.pdf(Z)\n",
    "                ei[pred_std_main == 0.] = 0.\n",
    "\n",
    "            GO_table[\"Acquisition_main\"] = ei\n",
    "\n",
    "            #Calculation of sub acquisition function\n",
    "            pred_mean_sub, pred_var_sub = gpy_model_sub.predict(points)\n",
    "            pred_mean_sub = pred_mean_sub.reshape(-1)\n",
    "            pred_std_sub = np.sqrt(pred_var_sub.reshape(-1))\n",
    "            GO_table[\"pred_mean_sub\"] = pred_mean_sub\n",
    "            GO_table[\"pred_std_sub\"] = pred_std_sub\n",
    "\n",
    "            #CFD of normal distribution (mu, std**2) from threshold_sub to infinity\n",
    "            erfc_param = -1 * (threshold_sub - pred_mean_sub) / (np.sqrt(2) * pred_std_sub)\n",
    "            GO_table[\"Acquisition_sub\"] = 1 - (0.5 * erfc(erfc_param))\n",
    "\n",
    "            #Calculation of total acquisition function\n",
    "            GO_table[\"Acquisition_total\"] = GO_table[\"Acquisition_main\"]*GO_table[\"Acquisition_sub\"]\n",
    "\n",
    "            for c in x_data_column:\n",
    "                GO_table[c] = 0.\n",
    "\n",
    "            GO_table.loc[:,x_data_column] = mmscaler.inverse_transform(points)\n",
    "\n",
    "            GO_table = GO_table.sort_values(\"Acquisition_total\", ascending=False)\n",
    "            GO_table[:1000].to_csv(f\"./GP/GP_{i}.csv\")\n",
    "\n",
    "            next_index = len(exp_table)+1\n",
    "            exp_table.loc[next_index] = -1\n",
    "            top_data = GO_table.iloc[0]\n",
    "            for clm in x_data_column:\n",
    "                exp_table.loc[next_index, clm] = top_data[clm]\n",
    "            exp_table.loc[next_index, output_label_main] = top_data[\"pred_mean_main_real\"]\n",
    "            exp_table.loc[next_index, output_label_sub] = top_data[\"pred_mean_sub\"]\n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(\"[ERROR] The setting 'BOA' must be 1 or 2.\")\n",
    "    \n",
    "    for i in range(len(exp_table)+1):\n",
    "        if i > original_size:\n",
    "            exp_table.loc[i, output_label_main] = -1\n",
    "            exp_table.loc[i, output_label_sub] = -1\n",
    "    exp_table.to_excel(\"./GP/DoE_Result.xlsx\")\n",
    "    print(f\"[Done] {time.time()-start:.2f}[sec]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b14ca20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
