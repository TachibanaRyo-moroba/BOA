{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121c4eab",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GPy in c:\\program files\\anaconda3\\lib\\site-packages (1.9.9)\n",
      "Requirement already satisfied: six in c:\\program files\\anaconda3\\lib\\site-packages (from GPy) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\program files\\anaconda3\\lib\\site-packages (from GPy) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.16 in c:\\program files\\anaconda3\\lib\\site-packages (from GPy) (1.4.1)\n",
      "Requirement already satisfied: paramz>=0.9.0 in c:\\program files\\anaconda3\\lib\\site-packages (from GPy) (0.9.5)\n",
      "Requirement already satisfied: decorator>=4.0.10 in c:\\program files\\anaconda3\\lib\\site-packages (from paramz>=0.9.0->GPy) (4.4.1)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\program files\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\program files\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\program files\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\program files\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1320 sha256=9e2aa9b2fa9395f3888a5eea5b1250cd4175d2ab0554e06c83425e0075533095\n",
      "  Stored in directory: c:\\users\\tachib0000\\appdata\\local\\pip\\cache\\wheels\\46\\ef\\c3\\157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n",
      "Requirement already satisfied: scipy in c:\\program files\\anaconda3\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\program files\\anaconda3\\lib\\site-packages (from scipy) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "#Run this block only if the modules below are not installed\n",
    "! pip install GPy\n",
    "! pip install sklearn\n",
    "! pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e20c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import norm\n",
    "import GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72954381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter setting\n",
    "BOA = 1   # 1 or 2\n",
    "number_of_experiments_per_cycle = 5\n",
    "\n",
    "#Label in DoE_Exp_Table_single_FoM.xlsx\n",
    "output_label = \"TON\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a14580",
   "metadata": {
    "code_folding": [
     41,
     100
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data read] factors: ['Substrate (mM)', 'Enzyme (uM)', 'pH', 'TPP (mM)', 'DMSO (%)']\n",
      "[ERROR] The setting 'BOA' must be 1 or 2.\n",
      "[Done] 0.05[sec]\n"
     ]
    }
   ],
   "source": [
    "xi = 0.01\n",
    "reject_rad = 1.\n",
    "core_opt = False\n",
    "\n",
    "if os.path.exists(\"./GP\"):\n",
    "    num = 1\n",
    "    while True:\n",
    "        if not os.path.exists(f\"./GP_prev{num}\"):\n",
    "            os.rename(\"./GP\", f\"./GP_prev{num}\")\n",
    "            break\n",
    "        else:\n",
    "            num += 1\n",
    "os.makedirs(\"./GP\", exist_ok=True)\n",
    "\n",
    "exp_table = pd.read_excel(\"./DoE_Exp_Table_single_FoM.xlsx\", index_col=0)\n",
    "exp_table.columns = [c.strip() for c in exp_table.columns]\n",
    "\n",
    "x_data_column = [c for c in exp_table.columns if not c==output_label]\n",
    "print(f\"[Data read] factors: {x_data_column}\")\n",
    "\n",
    "reso = 11\n",
    "if len(x_data_column) > 6:\n",
    "    print(\"[CAUTION] The number of the factors is large. The search grid resolution is lowered.\")\n",
    "    reso -= 2*(len(x_data_column)-6)\n",
    "    print(f\"Resolution={reso} (default:11)\")\n",
    "if reso < 5:\n",
    "    print(\"[ERROR] The grid resolution is too low. Use sciCORE instead of this laptop.\")\n",
    "    print(\"System terminated.\")\n",
    "else:\n",
    "\n",
    "    min_li = [exp_table.loc[\"MIN\", c] for c in x_data_column]\n",
    "    max_li = [exp_table.loc[\"MAX\", c] for c in x_data_column]\n",
    "    min_max_li = np.array([min_li, max_li], dtype=float)\n",
    "\n",
    "    mmscaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "    mmscaler.fit(min_max_li)\n",
    "\n",
    "    exp_table = exp_table.drop([\"MIN\", \"MAX\"])\n",
    "    original_size = len(exp_table)\n",
    "    start = time.time()\n",
    "    \n",
    "    if BOA == 1:\n",
    "        for i in range(1, number_of_experiments_per_cycle+1):\n",
    "            print(f\"[Cycle {i}] {time.time()-start:.2f}[sec]\")\n",
    "            #print(exp_table)\n",
    "            x_train = mmscaler.transform(exp_table.loc[:,x_data_column].values)\n",
    "            y_train = exp_table.loc[:,[output_label]].values\n",
    "\n",
    "            kern = GPy.kern.RBF(len(x_data_column), ARD=True)\n",
    "            gpy_model = GPy.models.GPRegression(X=x_train, Y=y_train, kernel=kern, normalizer=True)\n",
    "            if core_opt: gpy_model.optimize(messages=True, max_iters=1e5)\n",
    "\n",
    "            lis = []\n",
    "            for j in range(len(x_data_column)):\n",
    "                lis += [np.linspace(0, 1.0, reso)]\n",
    "            points = np.array(list(itertools.product(*lis)))\n",
    "\n",
    "            minDist = distance.cdist(points, x_train, metric='euclidean').min(axis=1)\n",
    "            points = points[minDist>0.01]\n",
    "\n",
    "            if i > 1:\n",
    "                x_train_tentative = x_train[-(i-1):,:]\n",
    "                #print(x_train_tentative)\n",
    "                minDist = distance.cdist(points, x_train_tentative, metric='euclidean').min(axis=1)\n",
    "                points = points[minDist>reject_rad]\n",
    "\n",
    "            GO_table = pd.DataFrame(points, columns=[f\"{c}_S\" for c in x_data_column])\n",
    "\n",
    "            pred_mean, pred_var = gpy_model.predict(points)\n",
    "            pred_mean = pred_mean.reshape(-1)\n",
    "            pred_std = np.sqrt(pred_var.reshape(-1))\n",
    "            GO_table[\"pred_mean\"] = pred_mean\n",
    "            GO_table[\"pred_std\"] = pred_std\n",
    "\n",
    "            mu_sample, _ = gpy_model.predict(x_train)\n",
    "            mu_sample_opt = np.max(mu_sample)\n",
    "\n",
    "            with np.errstate(divide='warn'):\n",
    "                imp = pred_mean - mu_sample_opt - xi\n",
    "                Z = imp / pred_std\n",
    "                ei = imp * norm.cdf(Z) + pred_std * norm.pdf(Z)\n",
    "                ei[pred_std == 0.] = 0.\n",
    "\n",
    "            GO_table[\"Acquisition\"] = ei\n",
    "\n",
    "            for c in x_data_column:\n",
    "                GO_table[c] = 0.\n",
    "\n",
    "            GO_table.loc[:,x_data_column] = mmscaler.inverse_transform(points)\n",
    "\n",
    "            GO_table = GO_table.sort_values(\"Acquisition\", ascending=False)\n",
    "            GO_table[:1000].to_csv(f\"./GP/GP_{i}.csv\")\n",
    "\n",
    "            next_index = len(exp_table)+1\n",
    "            exp_table.loc[next_index] = -1\n",
    "            top_data = GO_table.iloc[0]\n",
    "            for clm in x_data_column:\n",
    "                exp_table.loc[next_index, clm] = top_data[clm]\n",
    "            exp_table.loc[next_index, output_label] = top_data[\"pred_mean\"]\n",
    "        \n",
    "    elif BOA == 2:\n",
    "        for i in range(1, number_of_experiments_per_cycle+1):\n",
    "            print(f\"[Cycle {i}] {time.time()-start:.2f}[sec]\")\n",
    "            x_train = mmscaler.transform(exp_table.loc[:,x_data_column].values)\n",
    "            y_train_raw = exp_table.loc[:,[output_label]].values\n",
    "\n",
    "            #scaling y\n",
    "            y_scale_val = y_train_raw.max()/10.\n",
    "            y_train = y_train_raw/y_scale_val\n",
    "\n",
    "            kern = GPy.kern.RBF(len(x_data_column), ARD=True)\n",
    "            gpy_model = GPy.models.GPRegression(X=x_train, Y=y_train, kernel=kern, normalizer=True)\n",
    "            if core_opt: gpy_model.optimize(messages=True, max_iters=1e5)\n",
    "\n",
    "            lis = []\n",
    "            for j in range(len(x_data_column)):\n",
    "                lis += [np.linspace(0, 1.0, reso)]\n",
    "            points = np.array(list(itertools.product(*lis)))\n",
    "\n",
    "            minDist = distance.cdist(points, x_train, metric='euclidean').min(axis=1)\n",
    "            points = points[minDist>0.01]\n",
    "\n",
    "            GO_table = pd.DataFrame(points, columns=[f\"{c}_S\" for c in x_data_column])\n",
    "\n",
    "            pred_mean, pred_var = gpy_model.predict(points)\n",
    "            pred_mean = pred_mean.reshape(-1)\n",
    "            pred_std = pred_var.reshape(-1)\n",
    "            GO_table[\"pred_mean_real\"] = pred_mean*y_scale_val\n",
    "            GO_table[\"pred_mean_scaled\"] = pred_mean\n",
    "            GO_table[\"pred_std\"] = pred_std\n",
    "\n",
    "            mu_sample, _ = gpy_model.predict(x_train)\n",
    "            mu_sample_opt = np.max(mu_sample)\n",
    "\n",
    "            with np.errstate(divide='warn'):\n",
    "                imp = pred_mean - mu_sample_opt - xi\n",
    "                Z = imp / pred_std\n",
    "                ei = imp * norm.cdf(Z) + pred_std * norm.pdf(Z)\n",
    "                ei[pred_std == 0.] = 0.\n",
    "\n",
    "            GO_table[\"Acquisition\"] = ei\n",
    "\n",
    "            for c in x_data_column:\n",
    "                GO_table[c] = 0.\n",
    "\n",
    "            GO_table.loc[:,x_data_column] = mmscaler.inverse_transform(points)\n",
    "\n",
    "            GO_table = GO_table.sort_values(\"Acquisition\", ascending=False)\n",
    "            GO_table[:1000].to_csv(f\"./GP/GP_{i}.csv\")\n",
    "\n",
    "            next_index = len(exp_table)+1\n",
    "            exp_table.loc[next_index] = -1\n",
    "            top_data = GO_table.iloc[0]\n",
    "            for clm in x_data_column:\n",
    "                exp_table.loc[next_index, clm] = top_data[clm]\n",
    "            exp_table.loc[next_index, output_label] = top_data[\"pred_mean_real\"]\n",
    "            \n",
    "    else:\n",
    "        print(\"[ERROR] The setting 'BOA' must be 1 or 2.\")\n",
    "        \n",
    "    for i in range(len(exp_table)+1):\n",
    "        if i > original_size:\n",
    "            exp_table.loc[i, output_label] = -1\n",
    "    exp_table.to_excel(\"./GP/DoE_Result.xlsx\")\n",
    "    print(f\"[Done] {time.time()-start:.2f}[sec]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6697f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
